<!DOCTYPE html>
<html>
	<head>
		<meta charset='utf-8'>
		<meta http-equiv="X-UA-Compatible" content="chrome=1">
		<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
		<link href='https://fonts.googleapis.com/css?family=Architects+Daughter' rel='stylesheet' type='text/css'>
		<link rel="stylesheet" type="text/css" href="stylesheets/stylesheet.css" media="screen">
		<link rel="stylesheet" type="text/css" href="stylesheets/github-light.css" media="screen">
		<link rel="stylesheet" type="text/css" href="stylesheets/print.css" media="print">
<style>
.accordion {
    background-color: #fbfbfb;
    color: #444;
    cursor: pointer;
    padding: 7px;
    width: 100%;
    border: none;
    text-align: left;
    outline: none;
    font-size: 14px;
    transition: 0.4s;
}

.active, .accordion:hover {
    background-color: #ccc; 
}

.active, .h2:hover {
    background-color: #fbfbfb; 
}

.panel {
    padding: 0 14px;
    display: none;
    background-color: #fbfbfb;
    overflow: hidden;
}
</style>
		<!--[if lt IE 9]>
		<script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
		<![endif]-->

		<title>PLSMS</title>
	</head>

<body>

	<header>
	<div class="inner">
	<h1>PLSMS.github.io</h1>
	<h2>Welcome to the personal site of PLSMS!</h2>
	<a href="https://github.com/plsms" class="button"><small>Follow me on</small> GitHub</a>
	</div>
	</header>

	<div id="content-wrapper">
	<div class="inner clearfix">
	
	<section id="main-content">

	
		<h1 id="machine-learning"><a href="https://github.com/plsms/Machine-Learning" target="_blank">Machine Learning</a></h1>
		
		<button class="accordion h2"><h2>Part 1 - Data Preprocessing</h2></button>
		<div class="panel">
			<button class="accordion">Section 02 - Data Preprocessing</button>
			<div class="panel"><ul>
				<li>Getting the dataset</li>
				<li>Importing the Libraries</li>
				<li>Importing the Dataset</li>
				<li>For Python learners, summary of Object-oriented programming: classes & objects</li>
				<li>Missing Data</li>
				<li>Splitting the Dataset into the Training set and Test set</li>
				<li>Feature Scaling</li>
				<li>Data Preprocessing Template</li>
			</ul></div>
		</div>
			
		<button class="accordion h2"><h2>Part 2 - Regression</h2></button>
		<div class="panel">
		

			
			<button class="accordion">Section 04 - Simple Linear Regression</button>
			<div class="panel"><ul>
				<li>Simple Linear Regression Intuition</li>
				<li>Simple Linear Regression in Python</li>
					<ul>
					<li>Importing the libraries</li>
					<li>Importing the dataset</li>
					<li>Splitting the dataset into the Training set and Test set</li>
					<li>Feature Scaling</li>
					<li>Fitting Simple Linear Regression to the Training set</li>
					<li>Predicting the Test set results</li>
					<li>Visualising the Training set results</li>
					<p><a href="https://i.imgur.com/o4D1Mbj.png" target="_blank"><img src="https://i.imgur.com/o4D1Mbj.png"/></a></p>
					<li>Visualising the Test set results</li>
					<p><a href="https://i.imgur.com/MqnOpGE.png" target="_blank"><img src="https://i.imgur.com/MqnOpGE.png"/></a></p>
					</ul>
				<li>Simple Linear Regression in Python - Backward Elimination</li>
				<li>Simple Linear Regression in R</li>
					<ul>
					<li>Importing the dataset</li>
					<li>Splitting the dataset into the Training set and Test set</li>
					<li>Feature Scaling</li>
					<li>Fitting Simple Linear Regression to the Training set</li>
					<li>Predicting the Test set results</li>
					<li>Visualising the Training set results</li>
					<p><a href="" target="_blank"><img src=""/></a></p>
					<li>Visualising the Test set results</li>
					<p><a href="" target="_blank"><img src=""/></a></p>
					</ul>
				<li>Simple Linear Regression in R - Backward Elimination</li>
			</ul></div>

			<button class="accordion">Section 05 - Multiple Linear Regression</button>
			<div class="panel"><ul>
				<li>Multiple Linear Regression Intuition</li>
				<li>What is the P-Value?</li>
				<li>Multiple Linear Regression in Python</li>
					<ul>
					<li>Importing the libraries</li>
					<li>Importing the dataset</li>
					<li>Encoding categorical data</li>
					<li>Avoiding the Dummy Variable Trap</li>
					<li>Splitting the dataset into the Training set and Test set</li>
					<li>Feature Scaling</li>
					<li>Fitting Multiple Linear Regression to the Training set</li>
					<li>Predicting the Test set results</li>
					</ul>
				<li>Multiple Linear Regression in Python - Backward Elimination</li>
				<li>Multiple Linear Regression in Python - Automatic Backward Elimination</li>
				<li>Multiple Linear Regression in R</li>
					<ul>
					<li>Importing the dataset</li>
					<li>Encoding categorical data</li>
					<li>Splitting the dataset into the Training set and Test set</li>
					<li>Feature Scaling</li>
					<li>Fitting Multiple Linear Regression to the Training set</li>
					<li>Predicting the Test set results</li>
					</ul>
				<li>Multiple Linear Regression in R - Backward Elimination</li>
				<li>Multiple Linear Regression in R - Automatic Backward Elimination</li>
				<br><p><a href="https://i.imgur.com/u2B57rw.png" target="_blank"><img src="https://i.imgur.com/u2B57rw.png"/></a></p>
			</ul></div>

			<button class="accordion">Section 06 - Polynomial Regression</button>
			<div class="panel"><ul>
				<li>Polynomial Regression Intuition</li>
				<li>Polynomial Regression in Python</li>
					<ul>
					<li>Importing the libraries</li>
					<li>Importing the dataset</li>
					<li>Splitting the dataset into the Training set and Test set</li>
					<li>Feature Scaling</li>
					<li>Fitting Linear Regression to the dataset</li>
					<li>Fitting Polynomial Regression to the dataset</li>
					<li>Visualising the Linear Regression results</li>
					<p><a href="https://i.imgur.com/rjbFqiP.png" target="_blank"><img src="https://i.imgur.com/rjbFqiP.png"/></a></p></li>
					<li>Visualising the Polynomial Regression results</li>
					<p><a href="https://i.imgur.com/k00nLPk.png" target="_blank"><img src="https://i.imgur.com/k00nLPk.png"/></a></p></li>
					<li>Visualising the Polynomial Regression results (for higher resolution and smoother curve)</li>
					<p><a href="https://i.imgur.com/xbWsr1A.png" target="_blank"><img src="https://i.imgur.com/xbWsr1A.png"/></a></p>
					<li>Predicting a new result with Linear Regression</li>
					<li>Predicting a new result with Polynomial Regression</li>
					</ul>
				<li>Polynomial Regression in R</li>
					<ul>
					<li>Importing the dataset</li>
					<li>Splitting the dataset into the Training set and Test set</li>
					<li>Feature Scaling</li>
					<li>Fitting Linear Regression to the dataset</li>
					<li>Fitting Polynomial Regression to the dataset</li>
					<li>Visualising the Linear Regression results</li>
					<p><a href="" target="_blank"><img src=""/></a></p>
					<li>Visualising the Polynomial Regression results</li>
					<p><a href="" target="_blank"><img src=""/></a></p>
					<li>Visualising the Regression Model results (for higher resolution and smoother curve)</li>
					<p><a href="" target="_blank"><img src=""/></a></p>
					<li>Predicting a new result with Linear Regression</li>
					<li>Predicting a new result with Polynomial Regression</li>
					</ul>
			</ul></div>
			
			<button class="accordion">Section 07 - Support Vector Regression (SVR)</button>
			<div class="panel"><ul>
				<li>SVR Intuition</li>
				<li>SVR in Python</li>
					<ul>
					<li>Importing the libraries</li>
					<li>Importing the dataset</li>
					<li>Splitting the dataset into the Training set and Test set</li>
					<li>Feature Scaling</li>
					<li>Fitting SVR to the dataset</li>
					<li>Predicting a new result</li>
					<li>Visualising the SVR results</li>
					<p><a href="https://i.imgur.com/1eAJpqv.png" target="_blank"><img src="https://i.imgur.com/1eAJpqv.png"/></a></p>
					<li>Visualising the SVR results (for higher resolution and smoother curve)</li>
					<p><a href="https://i.imgur.com/a1tfyxE.png" target="_blank"><img src="https://i.imgur.com/a1tfyxE.png"/></a></p>
					</ul>
				<li>SVR in R</li>
					<ul>
					<li>Importing the dataset</li>
					<li>Splitting the dataset into the Training set and Test set</li>
					<li>Feature Scaling</li>
					<li>Fitting SVR to the dataset</li>
					<li>Predicting a new result</li>
					<li>Visualising the SVR results</li>
					<p><a href="" target="_blank"><img src=""/></a></p>
					<li>Visualising the SVR results (for higher resolution and smoother curve)</li>
					<p><a href="" target="_blank"><img src=""/></a></p>
					</ul>
			</ul></div>

			<button class="accordion">Section 08 - Decision Tree Regression</button>
			<div class="panel"><ul>
				<li>Decision Tree Regression Intuition</li>
				<li>Decision Tree Regression in Python</li>
					<ul>
					<li>Importing the libraries</li>
					<li>Importing the dataset</li>
					<li>Splitting the dataset into the Training set and Test set</li>
					<li>Feature Scaling</li>
					<li>Fitting Decision Tree Regression to the dataset</li>
					<li>Predicting a new result</li>
					<li>Visualising the Decision Tree Regression results (higher resolution)</li>
					<p><a href="https://i.imgur.com/iywSOrW.png" target="_blank"><img src="https://i.imgur.com/iywSOrW.png"/></a></p>
					</ul>
				<li>Decision Tree Regression in R</li>
					<ul>
					<li>Importing the dataset</li>
					<li>Splitting the dataset into the Training set and Test set</li>
					<li>Feature Scaling</li>
					<li>Fitting Decision Tree Regression to the dataset</li>
					<li>Predicting a new result with Decision Tree Regression</li>
					<li>Visualising the Decision Tree Regression results (higher resolution)</li>
					<p><a href="" target="_blank"><img src=""/></a></p>
					<li>Plotting the tree</li>
					</ul>
			</ul></div>
			
			<button class="accordion">Section 09 - Random Forest Regression</button>
			<div class="panel"><ul>
				<li>Random Forest Regression Intuition</li>
				<li>Random Forest Regression in Python</li>
					<ul>
					<li>Importing the libraries</li>
					<li>Importing the dataset</li>
					<li>Splitting the dataset into the Training set and Test set</li>
					<li>Feature Scaling</li>
					<li>Fitting Random Forest Regression to the dataset</li>
					<li>Predicting a new result</li>
					<li>Visualising the Random Forest Regression results (higher resolution)</li>
					<p><a href="https://i.imgur.com/HbvWbKW.png" target="_blank"><img src="https://i.imgur.com/HbvWbKW.png"/></a></p>
					</ul>
				<li>Random Forest Regression in R</li>
					<ul>
					<li>Importing the dataset</li>
					<li>Splitting the dataset into the Training set and Test set</li>
					<li>Feature Scaling</li>
					<li>Fitting Random Forest Regression to the dataset</li>
					<li>Predicting a new result with Random Forest Regression</li>
					<li>Visualising the Random Forest Regression results (higher resolution)</li>
					<p><a href="" target="_blank"><img src=""/></a></p>
					</ul>
			</ul></div>
			
			<button class="accordion">Section 10 - Evaluating Regression Models Performance</button>
			<div class="panel">
				<ul>
				<li>R-Squared Intuition</li>
				<li>Adjusted R-Squared Intuition</li>
				<li>Evaluating Regression Models Performance</li>
				<li>Interpreting Linear Regression Coefficients</li>
				<br><p><a href="https://i.imgur.com/QKobqHQ.png" target="_blank"><img src="https://i.imgur.com/QKobqHQ.png"/></a></p>
				</ul>
			</div>
			
			<button class="accordion">Section 11 - Regularization Methods</button>
			<div class="panel">
				<br><p><a href="https://i.imgur.com/vvRcnNx.png" target="_blank"><img src="https://i.imgur.com/vvRcnNx.png"/></a></p>
			</div>
			
		</div>
		
		<button class="accordion h2"><h2>Part 3 - Classification</h2></button>
		<div class="panel">
		
			<button class="accordion">Section 14 - Logistic Regression</button>
			<div class="panel"><ul>
				<li>Logistic Regression Intuition</li>
				<li>Logistic Regression in Python</li>
					<ul>
					<li>Importing the libraries</li>
					<li>Importing the dataset</li>
					<li>Splitting the dataset into the Training set and Test set</li>
					<li>Feature Scaling</li>
					<li>Fitting Logistic Regression to the Training set</li>
					<li>Predicting the Test set results</li>
					<li>Making the Confusion Matrix</li>
					<li>Visualising the Training set results</li>
					<p><a href="https://i.imgur.com/9TvLeXn.png" target="_blank"><img src="https://i.imgur.com/9TvLeXn.png"/></a></p>
					<li>Visualising the Test set results</li>
					<p><a href="https://i.imgur.com/GoaXLp0.png" target="_blank"><img src="https://i.imgur.com/GoaXLp0.png"/></a></p>
					</ul>
			</ul></div>
			
			<button class="accordion">Section 15 - K-Nearest Neighbor (K-NN)</button>
			<div class="panel"><ul>
				<li>K-NN Intuition</li>
				<li>K-NN in Python</li>
					<ul>
					<li>Importing the libraries</li>
					<li>Importing the dataset</li>
					<li>Splitting the dataset into the Training set and Test set</li>
					<li>Feature Scaling</li>
					<li>Fitting K-NN to the Training set</li>
					<li>Predicting the Test set results</li>
					<li>Making the Confusion Matrix</li>
					<li>Visualising the Training set results</li>
					<p><a href="https://i.imgur.com/edd7MQe.png" target="_blank"><img src="https://i.imgur.com/edd7MQe.png"/></a></p>
					<li>Visualising the Test set results</li>
					<p><a href="https://i.imgur.com/6DTpxve.png" target="_blank"><img src="https://i.imgur.com/6DTpxve.png"/></a></p>
					</ul>
			</ul></div>
			
			<button class="accordion">Section 16 - Support Vector Machine (SVM)</button>
			<div class="panel"><ul>
				<li>SVM Intuition</li>
				<li>SVM in Python</li>
					<ul>
					<li>Importing the libraries</li>
					<li>Importing the dataset</li>
					<li>Splitting the dataset into the Training set and Test set</li>
					<li>Feature Scaling</li>
					<li>Fitting SVM to the Training set</li>
					<li>Predicting the Test set results</li>
					<li>Making the Confusion Matrix</li>
					<li>Visualising the Training set results</li>
					<p><a href="https://i.imgur.com/c97I9BI.png" target="_blank"><img src="https://i.imgur.com/c97I9BI.png"/></a></p>
					<li>Visualising the Test set results</li>
					<p><a href="https://i.imgur.com/ivA90a0.png" target="_blank"><img src="https://i.imgur.com/ivA90a0.png"/></a></p>
					</ul>
			</ul></div>
			
			<button class="accordion">Section 17 - Kernel SVM</button>
			<div class="panel"><ul>
				<li>Kernel SVM Intuition</li>
				<li>Mapping to a higher dimension</li>
				<li>The Kernel Trick</li>
				<li>Types of Kernel Functions</li>
				<li>Kernel SVM in Python</li>
					<ul>
					<li>Importing the libraries</li>
					<li>Importing the dataset</li>
					<li>Splitting the dataset into the Training set and Test set</li>
					<li>Feature Scaling</li>
					<li>Fitting Kernel SVM to the Training set</li>
					<li>Predicting the Test set results</li>
					<li>Making the Confusion Matrix</li>
					<li>Visualising the Training set results</li>
					<p><a href="https://i.imgur.com/uEZYTOA.png" target="_blank"><img src="https://i.imgur.com/uEZYTOA.png"/></a></p>
					<li>Visualising the Test set results</li>
					<p><a href="https://i.imgur.com/dy5An83.png" target="_blank"><img src="https://i.imgur.com/dy5An83.png"/></a></p>
					</ul>
			</ul></div>
			
			<button class="accordion">Section 18 - Naive Bayes</button>
			<div class="panel"><ul>
				<li>Bayes Theorem</li>
				<li>Naive Bayes Intuition</li>
				<li>Naive Bayes in Python</li>
					<ul>
					<li>Importing the libraries</li>
					<li>Importing the dataset</li>
					<li>Splitting the dataset into the Training set and Test set</li>
					<li>Feature Scaling</li>
					<li>Fitting Naive Bayes to the Training set</li>
					<li>Predicting the Test set results</li>
					<li>Making the Confusion Matrix</li>
					<li>Visualising the Training set results</li>
					<p><a href="https://i.imgur.com/TjFZZPE.png" target="_blank"><img src="https://i.imgur.com/TjFZZPE.png"/></a></p>
					<li>Visualising the Test set results</li>
					<p><a href="https://i.imgur.com/VosOR8Q.png" target="_blank"><img src="https://i.imgur.com/VosOR8Q.png"/></a></p>
					</ul>
			</ul></div>
			
			<button class="accordion">Section 19 - Decision Tree Classification</button>
			<div class="panel"><ul>
				<li>Decision Tree Classification Intuition</li>
				<li>Decision Tree Classification in Python</li>
					<ul>
					<li>Importing the libraries</li>
					<li>Importing the dataset</li>
					<li>Splitting the dataset into the Training set and Test set</li>
					<li>Feature Scaling</li>
					<li>Fitting Decision Tree Classification to the Training set</li>
					<li>Predicting the Test set results</li>
					<li>Making the Confusion Matrix</li>
					<li>Visualising the Training set results</li>
					<p><a href="https://i.imgur.com/dMwCYta.png" target="_blank"><img src="https://i.imgur.com/dMwCYta.png"/></a></p>
					<li>Visualising the Test set results</li>
					<p><a href="https://i.imgur.com/HrflMV2.png" target="_blank"><img src="https://i.imgur.com/HrflMV2.png"/></a></p>
					</ul>
			</ul></div>
			
			<button class="accordion">Section 20 - Random Forest Classification</button>
			<div class="panel"><ul>
				<li>Random Forest Classification Intuition</li>
				<li>Random Forest Classification in Python</li>
					<ul>
					<li>Importing the libraries</li>
					<li>Importing the dataset</li>
					<li>Splitting the dataset into the Training set and Test set</li>
					<li>Feature Scaling</li>
					<li>Fitting Random Forest Classification to the Training set</li>
					<li>Predicting the Test set results</li>
					<li>Making the Confusion Matrix</li>
					<li>Visualising the Training set results</li>
					<p><a href="https://i.imgur.com/oKlmzdB.png" target="_blank"><img src="https://i.imgur.com/oKlmzdB.png"/></a></p>
					<li>Visualising the Test set results</li>
					<p><a href="https://i.imgur.com/bDnXmLu.png" target="_blank"><img src="https://i.imgur.com/bDnXmLu.png"/></a></p>
					</ul>
			</ul></div>
			
			<button class="accordion">Section 21 - Evaluating Classification Models Performance</button>
			<div class="panel"><ul>
				<li>False Positives & False Negatives</li>
				<li>Confusion Matrix</li>
				<li>Accuracy Paradox</li>
				<li>CAP Curve</li>
				<li>CAP Curve Analysis</li>
				<br><p><a href="https://i.imgur.com/q6NJw8X.png" target="_blank"><img src="https://i.imgur.com/q6NJw8X.png"/></a></p>
			</ul></div>
			
			<button class="accordion">Section 22 - Part Recap</button>
			<div class="panel"></div>
			
		</div>
			
		<button class="accordion h2"><h2>Part 4 - Clustering</h2></button>
		<div class="panel">
		
			<button class="accordion">Section 24 - K-Means Clustering</button>
			<div class="panel"><ul>
				<li>K-Means Clustering Intuition</li>
				<li>K-Means Random Initialization Trap</li>
				<li>K-Means Selecting The Number Of Clusters</li>
				<li>K-Means Clustering in Python</li>
					<ul>
					<li>Importing the libraries</li>
					<li>Importing the dataset</li>
					<li>Using the elbow method to find the optimal number of clusters</li>
					<p><a href="https://i.imgur.com/rGHiwYZ.png" target="_blank"><img src="https://i.imgur.com/rGHiwYZ.png"/></a></p>
					<li>Fitting K-Means to the dataset</li>
					<li>Visualising the clusters</li>
					<p><a href="https://i.imgur.com/KSVgNYm.png" target="_blank"><img src="https://i.imgur.com/KSVgNYm.png"/></a></p>
					</ul>
			</ul></div>
			
			<button class="accordion">Section 25 - Hierarchical Clustering</button>
			<div class="panel"><ul>
				<li>Hierarchical Clustering Intuition</li>
				<li>Hierarchical Clustering How Dendrograms Work</li>
				<li>Hierarchical Clustering Using Dendrograms</li>
				<li>HC in Python</li>
					<ul>
					<li>Importing the libraries</li>
					<li>Importing the dataset</li>
					<li>Using the dendrogram to find the optimal number of clusters</li>
					<p><a href="https://i.imgur.com/9xR3z3q.png" target="_blank"><img src="https://i.imgur.com/9xR3z3q.png"/></a></p>
					<li>Fitting Hierarchical Clustering to the dataset</li>
					<li>Visualising the clusters</li>
					<p><a href="https://i.imgur.com/dDVKAju.png" target="_blank"><img src="https://i.imgur.com/dDVKAju.png"/></a></p>
					</ul>
			</ul></div>
			
			<button class="accordion">Section 26 - Part Recap</button>
			<div class="panel"><ul>
				<p><a href="https://i.imgur.com/NnVCedo.png" target="_blank"><img src="https://i.imgur.com/NnVCedo.png"/></a></p>
			</ul></div>
			
		</div>
		
		<button class="accordion h2"><h2>Part 5 - Association Rule Learning</h2></button>
		<div class="panel">
		
			<button class="accordion">Section 28 - Apriori</button>
			<div class="panel"><ul>
				<li>Apriori Intuition</li>
				<li>Apriori in Python</li>
					<ul>
					<li>Importing the libraries</li>
					<li>Data Preprocessing</li>
					<li>Training Apriori on the dataset</li>
					<li>Visualising the results</li>
					</ul>
			</ul></div>
			
			<button class="accordion">Section 29 - Eclat</button>
			<div class="panel"><ul>
				<li>Eclat Intuition</li>
			</ul></div>
			
			<button class="accordion">Section 30 - Part Recap</button>
			<div class="panel"></div>
		
		</div>
		
		<button class="accordion h2"><h2>Part 6 - Reinforcement Learning</h2></button>
		<div class="panel">
		
			<button class="accordion">Section 32 - Upper Confidence Bound (UCB)</button>
			<div class="panel"><ul>
				<li>The Multi-Armed Bandit Problem</li>
				<li>Upper Confidence Bound (UCB) Intuition</li>
				<li>Random Selection in Python</li>
					<ul>
					<li>Importing the libraries</li>
					<li>Importing the dataset</li>
					<li>Implementing Random Selection</li>
					<li>Visualising the results</li>
					<p><a href="https://i.imgur.com/E8MsnPC.png" target="_blank"><img src="https://i.imgur.com/E8MsnPC.png"/></a></p>
					</ul>
				<li>Upper Confidence Bound in Python</li>
					<ul>
					<li>Importing the libraries</li>
					<li>Importing the dataset</li>
					<li>Implementing UCB</li>
<div class="language-js highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Implementing UCB
import math
N = 10000
d = 10
ads_selected = []
numbers_of_selections = [0] * d
sums_of_rewards = [0] * d
total_reward = 0
for n in range(0, N):
	ad = 0
	max_upper_bound = 0
	for i in range(0, d):
		if (numbers_of_selections[i] > 0):
			average_reward = sums_of_rewards[i] / numbers_of_selections[i]
			delta_i = math.sqrt(3/2 * math.log(n + 1) / numbers_of_selections[i])
			upper_bound = average_reward + delta_i
		else:
			upper_bound = 1e400
		if upper_bound > max_upper_bound:
			max_upper_bound = upper_bound
			ad = i
	ads_selected.append(ad)
	numbers_of_selections[ad] = numbers_of_selections[ad] + 1
	reward = dataset.values[n, ad]
	sums_of_rewards[ad] = sums_of_rewards[ad] + reward
	total_reward = total_reward + reward</span></code></pre></div></div>
					<p><a href="https://i.imgur.com/nuF9nK9.jpg" target="_blank"><img src="https://i.imgur.com/nuF9nK9.jpg"/></a></p>
					<li>Visualising the results</li>
					<p><a href="https://i.imgur.com/GbkgoC0.png" target="_blank"><img src="https://i.imgur.com/GbkgoC0.png"/></a></p>
					</ul>
			</ul></div>
			
			<button class="accordion">Section 33 - Thompson Sampling</button>
			<div class="panel"><ul>
				<li>Thompson Sampling Intuition</li>
				<li>Algorithm Comparison: UCB vs Thompson Sampling</li>
				<li>Thompson Sampling in Python </li>
					<ul>
					<li>Importing the libraries</li>
					<li>Importing the dataset</li>
					<li>Implementing Thompson Sampling</li>
<div class="language-js highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Implementing Thompson Sampling
import random
N = 10000
d = 10
ads_selected = []
numbers_of_rewards_1 = [0] * d
numbers_of_rewards_0 = [0] * d
total_reward = 0
for n in range(0, N):
    ad = 0
    max_random = 0
    for i in range(0, d):
        random_beta = random.betavariate(numbers_of_rewards_1[i] + 1, numbers_of_rewards_0[i] + 1)
        if random_beta > max_random:
            max_random = random_beta
            ad = i
    ads_selected.append(ad)
    reward = dataset.values[n, ad]
    if reward == 1:
        numbers_of_rewards_1[ad] = numbers_of_rewards_1[ad] + 1
    else:
        numbers_of_rewards_0[ad] = numbers_of_rewards_0[ad] + 1
    total_reward = total_reward + reward</span></code></pre></div></div>
					<p><a href="https://i.imgur.com/re1fNzl.jpg" target="_blank"><img src="https://i.imgur.com/re1fNzl.jpg"/></a></p>
					<li>Visualising the results - Histogram</li>
					<p><a href="https://i.imgur.com/bE4kFq8.png" target="_blank"><img src="https://i.imgur.com/bE4kFq8.png"/></a></p>
					</ul>
			</ul></div>
			
			<button class="accordion">Section 34 - Part Recap</button>
			<div class="panel"></div>
		
		</div>
		
		<button class="accordion h2"><h2>Part 7 - Natural Language Processing</h2></button>
		<div class="panel">
		
			<button class="accordion">Section 36 - Natural Language Processing</button>
			<div class="panel"><ul>
				<li>Natural Language Processing Intuition</li>
				<li>Natural Language Processing in Python</li>
					<ul>
					<li>Importing the libraries</li>
					<li>Importing the dataset</li>
					<li>Cleaning the texts</li>
					<li>Creating the Bag of Words model</li>
					<li>Splitting the dataset into the Training set and Test set</li>
					<li>Fitting Naive Bayes to the Training set</li>
					<li>Predicting the Test set results</li>
					<li>Making the Confusion Matrix</li>
			</ul></div>
			
			<button class="accordion">Section 37 - Part Recap</button>
			<div class="panel"></div>
		
		</div>
		
		<button class="accordion h2"><h2>Part 8 - Deep Learning</h2></button>
		<div class="panel">
		
			<button class="accordion">Section 38 - What is Deep Learning?</button>
			<div class="panel"></div>
		
			<button class="accordion">Section 39 - Artificial Neural Networks (ANN)</button>
			<div class="panel"><ul>
				<li>Plan of attack</li>
				<li>The Neuron</li>
				<li>The Activation Function</li>
				<li>How do Neural Networks work?</li>
				<li>How do Neural Networks learn?</li>
				<li>Gradient Descent</li>
				<li>Stochastic Gradient Descent</li>
				<li>Backpropagation</li>
				<li>Business Problem Description</li>
				<li>ANN in Python - Installing Theano, Tensorflow and Keras</li>
				<li>ANN in Python</li>
					<ul>
					<li>Installing Theano, Tensorflow and Keras</li>
					<li>Python</li>
					<li>Python</li>
					<li>Python</li>
					<li>Python</li>
					<li>Visualization</li>
					<p><a href="" target="_blank"><img src=""/></a></p>
					<li>Visualization</li>
					<p><a href="" target="_blank"><img src=""/></a></p>
					</ul>
			</ul></div>
			
			<button class="accordion">Section 40 - Convolutional Neural Networks (CNN)</button>
			<div class="panel"><ul>
				<li>Plan of attack</li>
				<li>What are convolutional neural networks?</li>
				<li>Step 1 - Convolution Operation</li>
				<li>Step 1(b) - ReLU Layer</li>
				<li>Step 2 - Pooling</li>
				<li>Step 3 - Flattening</li>
				<li>Step 4 - Full Connection</li>
				<li>Summary</li>
				<li>Softmax & Cross-Entropy</li>
				<li>CNN in Python</li>
					<ul>
					<li>Python</li>
					<li>Python</li>
					<li>Python</li>
					<li>Python</li>
					<li>Python</li>
					<li>Visualization</li>
					<p><a href="" target="_blank"><img src=""/></a></p>
					<li>Visualization</li>
					<p><a href="" target="_blank"><img src=""/></a></p>
					</ul>
			</ul></div>
			
			<button class="accordion">Section 41 - Part Recap</button>
			<div class="panel"><ul>
				<li>Intuition</li>
				<li>Python</li>
					<ul>
					<li>Python</li>
					<li>Python</li>
					<li>Python</li>
					<li>Python</li>
					<li>Python</li>
					<li>Visualization</li>
					<p><a href="" target="_blank"><img src=""/></a></p>
					<li>Visualization</li>
					<p><a href="" target="_blank"><img src=""/></a></p>
					</ul>
			</ul></div>
		
		</div>
		
		<button class="accordion h2"><h2>Part 9 - Dimensionality Reduction</h2></button>
		<div class="panel">
		
			<button class="accordion">Section 43 - Principal Component Analysis (PCA)</button>
			<div class="panel"><ul>
				<li>Principal Component Analysis (PCA) Intuition</li>
				<li>PCA in Python</li>
					<ul>
					<li>Python</li>
					<li>Python</li>
					<li>Python</li>
					<li>Python</li>
					<li>Python</li>
					<li>Visualization</li>
					<p><a href="" target="_blank"><img src=""/></a></p>
					<li>Visualization</li>
					<p><a href="" target="_blank"><img src=""/></a></p>
					</ul>
			</ul></div>
			
			<button class="accordion">Section 44 - Linear Discriminant Analysis (LDA)</button>
			<div class="panel"><ul>
				<li>Linear Discriminant Analysis (LDA) Intuition</li>
				<li>LDA in Python</li>
					<ul>
					<li>Python</li>
					<li>Python</li>
					<li>Python</li>
					<li>Python</li>
					<li>Python</li>
					<li>Visualization</li>
					<p><a href="" target="_blank"><img src=""/></a></p>
					<li>Visualization</li>
					<p><a href="" target="_blank"><img src=""/></a></p>
					</ul>
			</ul></div>
			
			<button class="accordion">Section 45 - Kernel PCA</button>
			<div class="panel"><ul>
				<li>Intuition</li>
				<li>Kernel PCA in Python</li>
					<ul>
					<li>Python</li>
					<li>Python</li>
					<li>Python</li>
					<li>Python</li>
					<li>Python</li>
					<li>Visualization</li>
					<p><a href="" target="_blank"><img src=""/></a></p>
					<li>Visualization</li>
					<p><a href="" target="_blank"><img src=""/></a></p>
					</ul>
			</ul></div>
			
			<button class="accordion">Section 46 - Part Recap</button>
			<div class="panel"><ul>
				<li>Intuition</li>
				<li>Python</li>
					<ul>
					<li>Python</li>
					<li>Python</li>
					<li>Python</li>
					<li>Python</li>
					<li>Python</li>
					<li>Visualization</li>
					<p><a href="" target="_blank"><img src=""/></a></p>
					<li>Visualization</li>
					<p><a href="" target="_blank"><img src=""/></a></p>
					</ul>
			</ul></div>
		
		</div>
		
		<button class="accordion h2"><h2>Part 10 - Model Selection & Boosting</h2></button>
		<div class="panel">
		
			<button class="accordion">Section 48 - Model Selection</button>
			<div class="panel"><ul>
				<li>k-Fold Cross Validation in Python</li>
					<ul>
					<li>Python</li>
					<li>Python</li>
					<li>Python</li>
					<li>Python</li>
					<li>Python</li>
					<li>Visualization</li>
					<p><a href="" target="_blank"><img src=""/></a></p>
					<li>Visualization</li>
					<p><a href="" target="_blank"><img src=""/></a></p>
					</ul>
				<li>Grid Search in Python </li>
					<ul>
					<li>Python</li>
					<li>Python</li>
					<li>Python</li>
					<li>Python</li>
					<li>Python</li>
					<li>Visualization</li>
					<p><a href="" target="_blank"><img src=""/></a></p>
					<li>Visualization</li>
					<p><a href="" target="_blank"><img src=""/></a></p>
					</ul>
			</ul></div>
			
			<button class="accordion">Section 49 - XGBoost</button>
			<div class="panel"><ul>
				<li>XGBoost in Python</li>
					<ul>
					<li>Python</li>
					<li>Python</li>
					<li>Python</li>
					<li>Python</li>
					<li>Python</li>
					<li>Visualization</li>
					<p><a href="" target="_blank"><img src=""/></a></p>
					<li>Visualization</li>
					<p><a href="" target="_blank"><img src=""/></a></p>
					</ul>
			</ul></div>
			
			<button class="accordion">Section 50 - Part Recap</button>
			<div class="panel"><ul>
				<li>Intuition</li>
				<li>Python</li>
					<ul>
					<li>Python</li>
					<li>Python</li>
					<li>Python</li>
					<li>Python</li>
					<li>Python</li>
					<li>Visualization</li>
					<p><a href="" target="_blank"><img src=""/></a></p>
					<li>Visualization</li>
					<p><a href="" target="_blank"><img src=""/></a></p>
					</ul>
			</ul></div>
		
	</section>

	<aside id="sidebar">
		<p>This page was generated by <a href="https://pages.github.com">GitHub Pages</a> using the Architect theme by <a href="https://twitter.com/jasonlong">Jason Long</a>.</p>
	</aside>
	
	</div>
	</div>
	

	
<script>
var acc = document.getElementsByClassName("accordion");
var i;

for (i = 0; i < acc.length; i++) {
    acc[i].addEventListener("click", function() {
        this.classList.toggle("active");
        var panel = this.nextElementSibling;
        if (panel.style.display === "block") {
            panel.style.display = "none";
        } else {
            panel.style.display = "block";
        }
    });
}
</script>

</body>
</html>
