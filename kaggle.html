<!DOCTYPE html>
<html>

<head>
	<meta charset='utf-8'>
	<meta http-equiv="X-UA-Compatible" content="chrome=1">
	<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
	<link href='https://fonts.googleapis.com/css?family=Architects+Daughter' rel='stylesheet' type='text/css'>
	<link rel="stylesheet" type="text/css" href="stylesheets/stylesheet.css" media="screen">
	<link rel="stylesheet" type="text/css" href="stylesheets/github-light.css" media="screen">
	<link rel="stylesheet" type="text/css" href="stylesheets/print.css" media="print">

	<style>
	.accordion {
		background-color: #fbfbfb;
		color: #444;
		cursor: pointer;
		padding: 7px;
		width: 100%;
		border: none;
		text-align: left;
		outline: none;
		font-size: 14px;
		transition: 0.4s;
	}

	.active, .accordion:hover {
		background-color: #ccc; 
	}

	.active, .h2:hover {
		background-color: #fbfbfb; 
	}

	.panel {
		padding: 0 14px;
		display: none;
		background-color: #fbfbfb;
		overflow: hidden;
	}
	</style>
			<!--[if lt IE 9]>
			<script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
			<![endif]-->

	<title>Kaggle | IPython notebooks from Kaggle.com</title>
</head>

<body>

<header>
<div class="inner">
<a href="https://plsms.github.io">
<h1>Kaggle</h1></a>
<h2>IPython notebooks from Kaggle.com</h2>
<a href="https://github.com/plsms/Kaggle" target="_blank" class="button"><small>View project on</small> GitHub</a>
</div>
</header>

<div id="content-wrapper"><div class="inner clearfix">

<section id="main-content">

	<h1 id="machine-learning"><a href="https://www.kaggle.com/learn" target="_blank">Learn</a></h1>
	
	<button class="accordion h2"><h2>Python</h2></button>
	<div class="panel">
		<p><b>01. Hello, Python</b>
		<a href="https://github.com/plsms/Kaggle/blob/master/Learn/1%20Python/01%20Hello%2C%20Python.ipynb" target="_blank">[Github]</a>
		<a href="https://www.kaggle.com/plsms21/hello-python" target="_blank">[Kaggle]</a>
		<br>A quick introduction to Python syntax, variable assignment, and numbers</p>
		
		<p><b>02. Exercise: Syntax, Variables, and Numbers</b>
		<a href="https://github.com/plsms/Kaggle/blob/master/Learn/1%20Python/02%20Exercise%3B%20Syntax%2C%20Variables%2C%20and%20Numbers.ipynb" target="_blank">[Github]</a>
		<a href="https://www.kaggle.com/plsms21/exercise-syntax-variables-and-numbers" target="_blank">[Kaggle]</a></p>
		
		<p><b>03. Functions and Getting Help</b>
		<a href="https://github.com/plsms/Kaggle/blob/master/Learn/1%20Python/03%20Functions%20and%20Getting%20Help.ipynb" target="_blank">[Github]</a>
		<a href="https://www.kaggle.com/plsms21/functions-and-getting-help" target="_blank">[Kaggle]</a>
		<br>Calling functions and defining our own, and using Python's builtin documentation
		<br><b>04. Exercise: Functions and Getting Help</b>
		<a href="https://github.com/plsms/Kaggle/blob/master/Learn/1%20Python/04%20Exercise%3B%20Functions%20and%20Getting%20Help.ipynb" target="_blank">[Github]</a>
		<a href="https://www.kaggle.com/plsms21/exercise-functions-and-getting-help" target="_blank">[Kaggle]</a></p>
		
		<p><b>05. Booleans and Conditionals</b>
		<a href="https://github.com/plsms/Kaggle/blob/master/Learn/1%20Python/05%20Booleans%20and%20Conditionals.ipynb" target="_blank">[Github]</a>
		<a href="https://www.kaggle.com/plsms21/booleans-and-conditionals" target="_blank">[Kaggle]</a>
		<br>Using booleans for branching logic
		<br><b>06. Exercise: Booleans and Conditionals</b>
		<a href="https://github.com/plsms/Kaggle/blob/master/Learn/1%20Python/06%20Exercise%3B%20Booleans%20and%20Conditionals.ipynb" target="_blank">[Github]</a>
		<a href="https://www.kaggle.com/plsms21/exercise-booleans-and-conditionals" target="_blank">[Kaggle]</a></p>
		
		<p><b>07. Lists</b>
		<a href="https://github.com/plsms/Kaggle/blob/master/Learn/1%20Python/07%20Lists.ipynb" target="_blank">[Github]</a>
		<a href="https://www.kaggle.com/plsms21/lists" target="_blank">[Kaggle]</a>
		<br>Lists and the things you can do with them. Includes indexing, slicing and mutating
		<br><b>08. Exercise: Lists</b>
		<a href="https://github.com/plsms/Kaggle/blob/master/Learn/1%20Python/08%20Exercise%3B%20Lists.ipynb" target="_blank">[Github]</a>
		<a href="https://www.kaggle.com/plsms21/exercise-lists" target="_blank">[Kaggle]</a></p>
		
		<p><b>09. Loops and List Comprehensions</b>
		<a href="https://github.com/plsms/Kaggle/blob/master/Learn/1%20Python/09%20Loops%20and%20List%20Comprehensions.ipynb" target="_blank">[Github]</a>
		<a href="https://www.kaggle.com/plsms21/loops-and-list-comprehensions" target="_blank">[Kaggle]</a>
		<br>For and while loops, and a much-loved Python feature: list comprehensions
		<br><b>10. Exercise: Loops and List Comprehensions</b>
		<a href="https://github.com/plsms/Kaggle/blob/master/Learn/1%20Python/10%20Exercise%3B%20Loops%20and%20List%20Comprehensions.ipynb" target="_blank">[Github]</a>
		<a href="https://www.kaggle.com/plsms21/exercise-loops-and-list-comprehensions" target="_blank">[Kaggle]</a></p>
		
		<p><b>11. Strings and Dictionaries</b>
		<a href="https://github.com/plsms/Kaggle/blob/master/Learn/1%20Python/11%20Strings%20and%20Dictionaries.ipynb" target="_blank">[Github]</a>
		<a href="https://www.kaggle.com/plsms21/strings-and-dictionaries" target="_blank">[Kaggle]</a>
		<br>Working with strings and dictionaries, two fundamental Python data types
		<br><b>12. Exercise: Strings and Dictionaries</b>
		<a href="https://github.com/plsms/Kaggle/blob/master/Learn/1%20Python/12%20Exercise%3B%20Strings%20and%20Dictionaries.ipynb" target="_blank">[Github]</a>
		<a href="https://www.kaggle.com/plsms21/exercise-strings-and-dictionaries" target="_blank">[Kaggle]</a></p>
		
		<p><b>13. Working with External Libraries</b>
		<a href="https://github.com/plsms/Kaggle/blob/master/Learn/1%20Python/13%20Working%20with%20External%20Libraries.ipynb" target="_blank">[Github]</a>
		<a href="https://www.kaggle.com/plsms21/working-with-external-libraries" target="_blank">[Kaggle]</a>
		<br>Imports, operator overloading, and survival tips for venturing into the world of external libraries
		<br><b>14. Exercise: Working with External Libraries</b>
		<a href="https://github.com/plsms/Kaggle/blob/master/Learn/1%20Python/14%20Exercise%3B%20Working%20with%20External%20Libraries.ipynb" target="_blank">[Github]</a>
		<a href="https://www.kaggle.com/plsms21/exercise-working-with-external-libraries" target="_blank">[Kaggle]</a></p>
	</div>
		
	<button class="accordion h2"><h2>Machine Learning</h2></button>
	<div class="panel">
		<p><b>LEVEL 1</b></p>
		
		<p><b>01. How Models Work</b>
		<a href="https://github.com/plsms/Kaggle/blob/master/Learn/2%20Machine%20Learning/Level%201/01%20How%20Models%20Work.ipynb" target="_blank">[Github]</a>
		<a href="https://www.kaggle.com/plsms21/how-models-work" target="_blank">[Kaggle]</a>
		<br>The first step if you're new to machine learning</p>
		
		<p><b>02. Explore Your Data</b>
		<a href="https://github.com/plsms/Kaggle/blob/master/Learn/2%20Machine%20Learning/Level%201/02%20Explore%20Your%20Data.ipynb" target="_blank">[Github]</a>
		<a href="https://www.kaggle.com/plsms21/explore-your-data" target="_blank">[Kaggle]</a>
		<br>Load data and set up your environment for your hands-on project
		<br><b>03. Exercise: Explore Your Data</b>
		<a href="https://github.com/plsms/Kaggle/blob/master/Learn/2%20Machine%20Learning/Level%201/03%20Exercise%3B%20Explore%20Your%20Data.ipynb" target="_blank">[Github]</a>
		<a href="https://www.kaggle.com/plsms21/exercise-explore-your-data" target="_blank">[Kaggle]</a></p>
		
		<p><b>04. Your First Machine Learning Model</b>
		<a href="https://github.com/plsms/Kaggle/blob/master/Learn/2%20Machine%20Learning/Level%201/04%20Your%20First%20Machine%20Learning%20Model.ipynb" target="_blank">[Github]</a>
		<a href="https://www.kaggle.com/plsms21/your-first-machine-learning-model" target="_blank">[Kaggle]</a>
		<br>Building your first model. Hurray!
		<br><b>05. Exercise: Your First Machine Learning Model</b>
		<a href="https://github.com/plsms/Kaggle/blob/master/Learn/2%20Machine%20Learning/Level%201/05%20Exercise%3B%20Your%20First%20Machine%20Learning%20Model.ipynb" target="_blank">[Github]</a>
		<a href="https://www.kaggle.com/plsms21/exercise-your-first-machine-learning-model" target="_blank">[Kaggle]</a></p>
		
		<p><b>06. Model Validation</b>
		<a href="https://github.com/plsms/Kaggle/blob/master/Learn/2%20Machine%20Learning/Level%201/06%20Model%20Validation.ipynb" target="_blank">[Github]</a>
		<a href="https://www.kaggle.com/plsms21/model-validation" target="_blank">[Kaggle]</a>
		<br>Measure the performance of your model ? so you can test and compare alternatives
		<br><b>07. Exercise: Model Validation</b>
		<a href="https://github.com/plsms/Kaggle/blob/master/Learn/2%20Machine%20Learning/Level%201/07%20Exercise%3B%20Model%20Validation.ipynb" target="_blank">[Github]</a>
		<a href="https://www.kaggle.com/plsms21/exercise-model-validation" target="_blank">[Kaggle]</a></p>
		
		<p><b>08. Underfitting and Overfitting</b>
		<a href="https://github.com/plsms/Kaggle/blob/master/Learn/2%20Machine%20Learning/Level%201/08%20Underfitting%20and%20Overfitting.ipynb" target="_blank">[Github]</a>
		<a href="https://www.kaggle.com/plsms21/underfitting-and-overfitting" target="_blank">[Kaggle]</a>
		<br>Fine-tune your model for better performance.
		<br><b>09. Exercise: Underfitting and Overfitting</b>
		<a href="https://github.com/plsms/Kaggle/blob/master/Learn/2%20Machine%20Learning/Level%201/09%20Exercise%3B%20Underfitting%20and%20Overfitting.ipynb" target="_blank">[Github]</a>
		<a href="https://www.kaggle.com/plsms21/exercise-underfitting-and-overfitting" target="_blank">[Kaggle]</a></p>
		
		<p><b>10. Random Forests</b>
		<a href="https://github.com/plsms/Kaggle/blob/master/Learn/2%20Machine%20Learning/Level%201/10%20Random%20Forests.ipynb" target="_blank">[Github]</a>
		<a href="https://www.kaggle.com/plsms21/random-forests" target="_blank">[Kaggle]</a>
		<br>Using a more sophisticated machine learning algorithm.
		<br><b>11. Exercise: Random Forests</b>
		<a href="https://github.com/plsms/Kaggle/blob/master/Learn/2%20Machine%20Learning/Level%201/11%20Exercise%3B%20Random%20Forests.ipynb" target="_blank">[Github]</a>
		<a href="https://www.kaggle.com/plsms21/exercise-random-forests" target="_blank">[Kaggle]</a></p>
		
		<p><b>12. Exercise: Machine Learning Competitions</b>
		<a href="https://github.com/plsms/Kaggle/blob/master/Learn/2%20Machine%20Learning/Level%201/12%20Exercise%3B%20Machine%20Learning%20Competitions.ipynb" target="_blank">[Github]</a>
		<a href="https://www.kaggle.com/plsms21/exercise-machine-learning-competitions" target="_blank">[Kaggle]</a>
		<br>Enter the world of machine learning competitions to keep improving and see your progress</p>
		
		<p><b>LEVEL 2</b></p>
		
		<p><b>1a. Handling Missing Values</b>
		<a href="https://github.com/plsms/Kaggle/blob/master/Learn/2%20Machine%20Learning/Level%202/1a%20Handling%20Missing%20Values.ipynb" target="_blank">[Github]</a>
		<a href="https://www.kaggle.com/plsms21/handling-missing-values" target="_blank">[Kaggle]</a>
		<br>Learn multiple approaches for dealing with missing data fields
		<br><b>1b. Exercise: Handling Missing Values</b>
		<a href="https://github.com/plsms/Kaggle/blob/master/Learn/2%20Machine%20Learning/Level%202/1b%20Exercise%3B%20Handling%20Missing%20Values.ipynb" target="_blank">[Github]</a>
		<a href="https://www.kaggle.com/plsms21/exercise-handling-missing-values" target="_blank">[Kaggle]</a></p>
		
		<p><b>2a. Using Categorical Data with One Hot Encoding</b>
		<a href="https://github.com/plsms/Kaggle/blob/master/Learn/2%20Machine%20Learning/Level%202/2a%20Using%20Categorical%20Data%20with%20One%20Hot%20Encoding.ipynb" target="_blank">[Github]</a>
		<a href="https://www.kaggle.com/plsms21/using-categorical-data-with-one-hot-encoding" target="_blank">[Kaggle]</a>
		<br>Handle this important but challenging data type
		<br><b>2b. Exercise: Using Categorical Data with One Hot Encoding</b>
		<a href="https://github.com/plsms/Kaggle/blob/master/Learn/2%20Machine%20Learning/Level%202/2b%20Exercise%3B%20Using%20Categorical%20Data%20with%20One%20Hot%20Encoding.ipynb" target="_blank">[Github]</a>
		<a href="https://www.kaggle.com/plsms21/exercise-using-categorical-data-with-one-hot-enc" target="_blank">[Kaggle]</a></p>
		
		<p><b>3a. XGBoost</b>
		<a href="https://github.com/plsms/Kaggle/blob/master/Learn/2%20Machine%20Learning/Level%202/3a%20XGBoost.ipynb" target="_blank">[Github]</a>
		<a href="https://www.kaggle.com/plsms21/xgboost" target="_blank">[Kaggle]</a>
		<br>The most important technique for building high-performance models on conventional data (the type that fits in tables or data frames.)
		<br><b>3b. Exercise: XGBoost</b>
		<a href="https://github.com/plsms/Kaggle/blob/master/Learn/2%20Machine%20Learning/Level%202/3b%20Exercise%3B%20XGBoost.ipynb" target="_blank">[Github]</a>
		<a href="https://www.kaggle.com/plsms21/exercise-xgboost" target="_blank">[Kaggle]</a></p>
		
		<p><b>4a. Partial Dependence Plots</b>
		<a href="https://github.com/plsms/Kaggle/blob/master/Learn/2%20Machine%20Learning/Level%202/4a%20Partial%20Dependence%20Plots.ipynb" target="_blank">[Github]</a>
		<a href="https://www.kaggle.com/plsms21/partial-dependence-plots" target="_blank">[Kaggle]</a>
		<br>Extract insights from your models. Insights many didn't even realize were possible.
		<br><b>4b. Exercise: Partial Dependence Plots</b>
		<a href="https://github.com/plsms/Kaggle/blob/master/Learn/2%20Machine%20Learning/Level%202/4b%20Exercise%3B%20Partial%20Dependence%20Plots.ipynb" target="_blank">[Github]</a>
		<a href="https://www.kaggle.com/plsms21/exercise-partial-dependence-plots" target="_blank">[Kaggle]</a></p>
		
		<p><b>5a. Pipelines</b>
		<a href="https://github.com/plsms/Kaggle/blob/master/Learn/2%20Machine%20Learning/Level%202/5a%20Pipelines.ipynb" target="_blank">[Github]</a>
		<a href="https://www.kaggle.com/plsms21/pipelines" target="_blank">[Kaggle]</a>
		<br>Make your machine learning code cleaner and more professional
		<br><b>5b. Exercise: Pipelines</b>
		<a href="https://github.com/plsms/Kaggle/blob/master/Learn/2%20Machine%20Learning/Level%202/5b%20Exercise%3B%20Pipelines.ipynb" target="_blank">[Github]</a>
		<a href="https://www.kaggle.com/plsms21/exercise-pipelines" target="_blank">[Kaggle]</a></p>
		
		<p><b>6a. Cross-Validation</b>
		<a href="https://github.com/plsms/Kaggle/blob/master/Learn/2%20Machine%20Learning/Level%202/6a%20Cross-Validation.ipynb" target="_blank">[Github]</a>
		<a href="https://www.kaggle.com/plsms21/cross-validation" target="_blank">[Kaggle]</a>
		<br>Improve how you compare and choose models and data preprocessing
		<br><b>6b. Exercise: Cross-Validation</b>
		<a href="https://github.com/plsms/Kaggle/blob/master/Learn/2%20Machine%20Learning/Level%202/6b%20Exercise%3B%20Cross-Validation.ipynb" target="_blank">[Github]</a>
		<a href="https://www.kaggle.com/plsms21/exercise-cross-validation" target="_blank">[Kaggle]</a></p>
		
		<p><b>7a. Data Leakage</b>
		<a href="https://github.com/plsms/Kaggle/blob/master/Learn/2%20Machine%20Learning/Level%202/7a%20Data%20Leakage.ipynb" target="_blank">[Github]</a>
		<a href="https://www.kaggle.com/plsms21/data-leakage" target="_blank">[Kaggle]</a>
		<br>Identify and avoid one of the most common and costly mistakes in machine learning.
		<br><b>7b. Exercise: Data Leakage</b>
		<a href="https://github.com/plsms/Kaggle/blob/master/Learn/2%20Machine%20Learning/Level%202/7b%20Exercise%3B%20Data%20Leakage.ipynb" target="_blank">[Github]</a>
		<a href="https://www.kaggle.com/plsms21/exercise-data-leakage" target="_blank">[Kaggle]</a></p>
		
	</div>
	
	<button class="accordion h2"><h2>Pandas</h2></button>
	<div class="panel">
	
		<button class="accordion">Section 14 - Logistic Regression</button>
		<div class="panel"><ul>
			<li>Logistic Regression Intuition</li>
			<li><a href="https://github.com/plsms/Machine-Learning/blob/master/Part%2003%20-%20Classification/Section%2014%20-%20Logistic%20Regression/Logistic_Regression/logistic_regression.py" target="_blank">
			Logistic Regression in Python</a></li>
				<ul>
				<li>Importing the libraries</li>
				<li>Importing the dataset</li>
				<li>Splitting the dataset into the Training set and Test set</li>
				<li>Feature Scaling</li>
				<li>Fitting Logistic Regression to the Training set</li>
				<li>Predicting the Test set results</li>
				<li>Making the Confusion Matrix</li>
				<li>Visualising the Training set results</li>
				<p><a href="https://i.imgur.com/9TvLeXn.png" target="_blank"><img src="https://i.imgur.com/9TvLeXn.png"/></a></p>
				<li>Visualising the Test set results</li>
				<p><a href="https://i.imgur.com/GoaXLp0.png" target="_blank"><img src="https://i.imgur.com/GoaXLp0.png"/></a></p>
				</ul>
			<li><a href="https://github.com/plsms/Machine-Learning/blob/master/Part%2003%20-%20Classification/Section%2014%20-%20Logistic%20Regression/Logistic_Regression/logistic_regression.R" target="_blank">
			Logistic Regression in R</a></li>
				<ul>
				<li>Importing the dataset</li>
				<li>Encoding the target feature as factor</li>
				<li>Splitting the dataset into the Training set and Test set</li>
				<li>Feature Scaling</li>
				<li>Fitting Logistic Regression to the Training set</li>
				<li>Predicting the Test set results</li>
				<li>Making the Confusion Matrix</li>
				<li>Visualising the Training set results</li>
				<p><a href="https://i.imgur.com/Gu2YetI.png" target="_blank"><img src="https://i.imgur.com/Gu2YetI.png"/></a></p>
				<li>Visualising the Test set results</li>
				<p><a href="https://i.imgur.com/Lpf50q6.png" target="_blank"><img src="https://i.imgur.com/Lpf50q6.png"/></a></p>
				</ul>
		</ul></div>
		
		<button class="accordion">Section 15 - K-Nearest Neighbor (K-NN)</button>
		<div class="panel"><ul>
			<li>K-NN Intuition</li>
			<li><a href="https://github.com/plsms/Machine-Learning/blob/master/Part%2003%20-%20Classification/Section%2015%20-%20K-Nearest%20Neighbors%20(K-NN)/K_Nearest_Neighbors/knn.py" target="_blank">
			K-NN in Python</a></li>
				<ul>
				<li>Importing the libraries</li>
				<li>Importing the dataset</li>
				<li>Splitting the dataset into the Training set and Test set</li>
				<li>Feature Scaling</li>
				<li>Fitting K-NN to the Training set</li>
				<li>Predicting the Test set results</li>
				<li>Making the Confusion Matrix</li>
				<li>Visualising the Training set results</li>
				<p><a href="https://i.imgur.com/edd7MQe.png" target="_blank"><img src="https://i.imgur.com/edd7MQe.png"/></a></p>
				<li>Visualising the Test set results</li>
				<p><a href="https://i.imgur.com/6DTpxve.png" target="_blank"><img src="https://i.imgur.com/6DTpxve.png"/></a></p>
				</ul>
			<li><a href="https://github.com/plsms/Machine-Learning/blob/master/Part%2003%20-%20Classification/Section%2015%20-%20K-Nearest%20Neighbors%20(K-NN)/K_Nearest_Neighbors/knn.R" target="_blank">
			K-NN in R</a></li>
				<ul>
				<li>Importing the dataset</li>
				<li>Encoding the target feature as factor</li>
				<li>Splitting the dataset into the Training set and Test set</li>
				<li>Feature Scaling</li>
				<li>Fitting K-NN to the Training set and Predicting the Test set results</li>
				<li>Making the Confusion Matrix</li>
				<li>Visualising the Training set results</li>
				<p><a href="https://i.imgur.com/K0RjKS4.png" target="_blank"><img src="https://i.imgur.com/K0RjKS4.png"/></a></p>
				<li>Visualising the Test set results</li>
				<p><a href="https://i.imgur.com/6EZvkdL.png" target="_blank"><img src="https://i.imgur.com/6EZvkdL.png"/></a></p>
				</ul>
		</ul></div>
		
		<button class="accordion">Section 16 - Support Vector Machine (SVM)</button>
		<div class="panel"><ul>
			<li>SVM Intuition</li>
			<li><a href="https://github.com/plsms/Machine-Learning/blob/master/Part%2003%20-%20Classification/Section%2016%20-%20Support%20Vector%20Machine%20(SVM)/SVM/svm.py" target="_blank">
			SVM in Python</a></li>
				<ul>
				<li>Importing the libraries</li>
				<li>Importing the dataset</li>
				<li>Splitting the dataset into the Training set and Test set</li>
				<li>Feature Scaling</li>
				<li>Fitting SVM to the Training set</li>
				<li>Predicting the Test set results</li>
				<li>Making the Confusion Matrix</li>
				<li>Visualising the Training set results</li>
				<p><a href="https://i.imgur.com/c97I9BI.png" target="_blank"><img src="https://i.imgur.com/c97I9BI.png"/></a></p>
				<li>Visualising the Test set results</li>
				<p><a href="https://i.imgur.com/ivA90a0.png" target="_blank"><img src="https://i.imgur.com/ivA90a0.png"/></a></p>
				</ul>
			<li><a href="https://github.com/plsms/Machine-Learning/blob/master/Part%2003%20-%20Classification/Section%2016%20-%20Support%20Vector%20Machine%20(SVM)/SVM/svm.R" target="_blank">
			SVM in R</a></li>
				<ul>
				<li>Importing the dataset</li>
				<li>Encoding the target feature as factor</li>
				<li>Splitting the dataset into the Training set and Test set</li>
				<li>Feature Scaling</li>
				<li>Fitting SVM to the Training set</li>
				<li>Predicting the Test set results</li>
				<li>Making the Confusion Matrix</li>
				<li>Visualising the Training set results</li>
				<p><a href="https://i.imgur.com/whDvgJg.png" target="_blank"><img src="https://i.imgur.com/whDvgJg.png"/></a></p>
				<li>Visualising the Test set results</li>
				<p><a href="https://i.imgur.com/rQuyzv0.png" target="_blank"><img src="https://i.imgur.com/rQuyzv0.png"/></a></p>
				</ul>
		</ul></div>
		
		<button class="accordion">Section 17 - Kernel SVM</button>
		<div class="panel"><ul>
			<li>Kernel SVM Intuition</li>
			<li>Mapping to a higher dimension</li>
			<li>The Kernel Trick</li>
			<li>Types of Kernel Functions</li>
			<li><a href="https://github.com/plsms/Machine-Learning/blob/master/Part%2003%20-%20Classification/Section%2017%20-%20Kernel%20SVM/Kernel_SVM/kernel_svm.py" target="_blank">
			Kernel SVM in Python</a></li>
				<ul>
				<li>Importing the libraries</li>
				<li>Importing the dataset</li>
				<li>Splitting the dataset into the Training set and Test set</li>
				<li>Feature Scaling</li>
				<li>Fitting Kernel SVM to the Training set</li>
				<li>Predicting the Test set results</li>
				<li>Making the Confusion Matrix</li>
				<li>Visualising the Training set results</li>
				<p><a href="https://i.imgur.com/uEZYTOA.png" target="_blank"><img src="https://i.imgur.com/uEZYTOA.png"/></a></p>
				<li>Visualising the Test set results</li>
				<p><a href="https://i.imgur.com/dy5An83.png" target="_blank"><img src="https://i.imgur.com/dy5An83.png"/></a></p>
				</ul>
			<li><a href="https://github.com/plsms/Machine-Learning/blob/master/Part%2003%20-%20Classification/Section%2017%20-%20Kernel%20SVM/Kernel_SVM/kernel_svm.R" target="_blank">
			Kernel SVM in R</a></li>
				<ul>
				<li>Importing the dataset</li>
				<li>Encoding the target feature as factor</li>
				<li>Splitting the dataset into the Training set and Test set</li>
				<li>Feature Scaling</li>
				<li>Fitting Kernel SVM to the Training set</li>
				<li>Predicting the Test set results</li>
				<li>Making the Confusion Matrix</li>
				<li>Visualising the Training set results</li>
				<p><a href="https://i.imgur.com/JMh6vEk.png" target="_blank"><img src="https://i.imgur.com/JMh6vEk.png"/></a></p>
				<li>Visualising the Test set results</li>
				<p><a href="https://i.imgur.com/CzUNlVn.png" target="_blank"><img src="https://i.imgur.com/CzUNlVn.png"/></a></p>
				</ul>
		</ul></div>
		
		<button class="accordion">Section 18 - Naive Bayes</button>
		<div class="panel"><ul>
			<li>Bayes Theorem</li>
			<li>Naive Bayes Intuition</li>
			<li><a href="https://github.com/plsms/Machine-Learning/blob/master/Part%2003%20-%20Classification/Section%2018%20-%20Naive%20Bayes/Naive_Bayes/naive_bayes.py" target="_blank">
			Naive Bayes in Python</a></li>
				<ul>
				<li>Importing the libraries</li>
				<li>Importing the dataset</li>
				<li>Splitting the dataset into the Training set and Test set</li>
				<li>Feature Scaling</li>
				<li>Fitting Naive Bayes to the Training set</li>
				<li>Predicting the Test set results</li>
				<li>Making the Confusion Matrix</li>
				<li>Visualising the Training set results</li>
				<p><a href="https://i.imgur.com/TjFZZPE.png" target="_blank"><img src="https://i.imgur.com/TjFZZPE.png"/></a></p>
				<li>Visualising the Test set results</li>
				<p><a href="https://i.imgur.com/VosOR8Q.png" target="_blank"><img src="https://i.imgur.com/VosOR8Q.png"/></a></p>
				</ul>
			<li><a href="https://github.com/plsms/Machine-Learning/blob/master/Part%2003%20-%20Classification/Section%2018%20-%20Naive%20Bayes/Naive_Bayes/naive_bayes.R" target="_blank">
			Naive Bayes in R</a></li>
				<ul>
				<li>Importing the dataset</li>
				<li>Encoding the target feature as factor</li>
				<li>Splitting the dataset into the Training set and Test set</li>
				<li>Feature Scaling</li>
				<li>Fitting SVM to the Training set</li>
				<li>Predicting the Test set results</li>
				<li>Making the Confusion Matrix</li>
				<li>Visualising the Training set results</li>
				<p><a href="https://i.imgur.com/1KtP3mc.png" target="_blank"><img src="https://i.imgur.com/1KtP3mc.png"/></a></p>
				<li>Visualising the Test set results</li>
				<p><a href="https://i.imgur.com/p2oB58v.png" target="_blank"><img src="https://i.imgur.com/p2oB58v.png"/></a></p>
				</ul>
		</ul></div>
		
		<button class="accordion">Section 19 - Decision Tree Classification</button>
		<div class="panel"><ul>
			<li>Decision Tree Classification Intuition</li>
			<li><a href="https://github.com/plsms/Machine-Learning/blob/master/Part%2003%20-%20Classification/Section%2019%20-%20Decision%20Tree%20Classification/Decision_Tree_Classification/decision_tree_classification.py" target="_blank">
			Decision Tree Classification in Python</a></li>
				<ul>
				<li>Importing the libraries</li>
				<li>Importing the dataset</li>
				<li>Splitting the dataset into the Training set and Test set</li>
				<li>Feature Scaling</li>
				<li>Fitting Decision Tree Classification to the Training set</li>
				<li>Predicting the Test set results</li>
				<li>Making the Confusion Matrix</li>
				<li>Visualising the Training set results</li>
				<p><a href="https://i.imgur.com/dMwCYta.png" target="_blank"><img src="https://i.imgur.com/dMwCYta.png"/></a></p>
				<li>Visualising the Test set results</li>
				<p><a href="https://i.imgur.com/HrflMV2.png" target="_blank"><img src="https://i.imgur.com/HrflMV2.png"/></a></p>
				</ul>
			<li><a href="https://github.com/plsms/Machine-Learning/blob/master/Part%2003%20-%20Classification/Section%2019%20-%20Decision%20Tree%20Classification/Decision_Tree_Classification/decision_tree_classification.R" target="_blank">
			Decision Tree Classification in R</a></li>
				<ul>
				<li>Importing the dataset</li>
				<li>Encoding the target feature as factor</li>
				<li>Splitting the dataset into the Training set and Test set</li>
				<li>Feature Scaling</li>
				<li>Fitting Decision Tree Classification to the Training set</li>
				<li>Predicting the Test set results</li>
				<li>Making the Confusion Matrix</li>
				<li>Visualising the Training set results</li>
				<p><a href="https://i.imgur.com/8nBSiXs.png" target="_blank"><img src="https://i.imgur.com/8nBSiXs.png"/></a></p>
				<li>Visualising the Test set results</li>
				<p><a href="https://i.imgur.com/jU2TaEU.png" target="_blank"><img src="https://i.imgur.com/jU2TaEU.png"/></a></p>
				<li>Plotting the tree</li>
				<p><a href="https://i.imgur.com/uAjUtNS.png" target="_blank"><img src="https://i.imgur.com/uAjUtNS.png"/></a></p>
				</ul>
		</ul></div>
		
		<button class="accordion">Section 20 - Random Forest Classification</button>
		<div class="panel"><ul>
			<li>Random Forest Classification Intuition</li>
			<li><a href="https://github.com/plsms/Machine-Learning/blob/master/Part%2003%20-%20Classification/Section%2020%20-%20Random%20Forest%20Classification/Random_Forest_Classification/random_forest_classification.py" target="_blank">
			Random Forest Classification in Python</a></li>
				<ul>
				<li>Importing the libraries</li>
				<li>Importing the dataset</li>
				<li>Splitting the dataset into the Training set and Test set</li>
				<li>Feature Scaling</li>
				<li>Fitting Random Forest Classification to the Training set</li>
				<li>Predicting the Test set results</li>
				<li>Making the Confusion Matrix</li>
				<li>Visualising the Training set results</li>
				<p><a href="https://i.imgur.com/oKlmzdB.png" target="_blank"><img src="https://i.imgur.com/oKlmzdB.png"/></a></p>
				<li>Visualising the Test set results</li>
				<p><a href="https://i.imgur.com/bDnXmLu.png" target="_blank"><img src="https://i.imgur.com/bDnXmLu.png"/></a></p>
				</ul>
			<li><a href="https://github.com/plsms/Machine-Learning/blob/master/Part%2003%20-%20Classification/Section%2020%20-%20Random%20Forest%20Classification/Random_Forest_Classification/random_forest_classification.R" target="_blank">
			Random Forest Classification in R</a></li>
				<ul>
				<li>Importing the dataset</li>
				<li>Encoding the target feature as factor</li>
				<li>Splitting the dataset into the Training set and Test set</li>
				<li>Feature Scaling</li>
				<li>Fitting Random Forest Classification to the Training set</li>
				<li>Predicting the Test set results</li>
				<li>Making the Confusion Matrix</li>
				<li>Visualising the Training set results</li>
				<p><a href="https://i.imgur.com/h0icv3I.png" target="_blank"><img src="https://i.imgur.com/h0icv3I.png"/></a></p>
				<li>Visualising the Test set results</li>
				<p><a href="https://i.imgur.com/4RObaaA.png" target="_blank"><img src="https://i.imgur.com/4RObaaA.png"/></a></p>
				<li>Choosing the number of trees</li>
				<p><a href="https://i.imgur.com/e12eyIP.png" target="_blank"><img src="https://i.imgur.com/e12eyIP.png"/></a></p>
				</ul>
		</ul></div>
		
		<button class="accordion">Section 21 - Evaluating Classification Models Performance</button>
		<div class="panel"><ul>
			<li>False Positives & False Negatives</li>
			<li>Confusion Matrix</li>
			<li>Accuracy Paradox</li>
			<li>CAP Curve</li>
			<li>CAP Curve Analysis</li>
			<br><p><a href="https://i.imgur.com/q6NJw8X.png" target="_blank"><img src="https://i.imgur.com/q6NJw8X.png"/></a></p>
		</ul></div>
		
		<button class="accordion">Section 22 - Part Recap</button>
		<div class="panel"></div>
		
	</div>
		
	<button class="accordion h2"><h2>Data Visualisation</h2></button>
	<div class="panel">
		<p><b>1. Welcome to data visualization</b>
		<a href="" target="_blank">[Github]</a>
		<a href="" target="_blank">[Kaggle]</a>
		<a href="https://plsms.github.io/wbk/01wbk.%20Welcome%20to%20data%20visualization.html" target="_blank">[HTML]</a>
		<br>Overview of data visualization tools and course structure.</p>
		
		<p><b>2. Univariate plotting with pandas</b>
		<a href="" target="_blank">[Github]</a>
		<a href="" target="_blank">[Kaggle]</a>
		<a href="https://plsms.github.io/wbk/02wbk.%20Univariate%20plotting%20with%20pandas.html" target="_blank">[HTML]</a>
		<br>Learn the basic (and most important) types of graphs</p>
		
		<p><b>3. Bivariate plotting with pandas</b>
		<a href="" target="_blank">[Github]</a>
		<a href="" target="_blank">[Kaggle]</a>
		<a href="https://plsms.github.io/wbk/03wbk.%20Bivariate%20plotting%20with%20pandas.html" target="_blank">[HTML]</a>
		<br>Visually capture the patterns and correlations in any dataset.</p>
		
		<p><b>4. Styling your plots</b>
		<a href="" target="_blank">[Github]</a>
		<a href="" target="_blank">[Kaggle]</a>
		<a href="https://plsms.github.io/wbk/04wbk.%20Styling%20your%20plots.html" target="_blank">[HTML]</a>
		<br>Make your plots look beautiful ? a key task before sharing</p>
		
		<p><b>5. Subplots</b>
		<a href="" target="_blank">[Github]</a>
		<a href="" target="_blank">[Kaggle]</a>
		<a href="https://plsms.github.io/wbk/05wbk.%20Subplots.html" target="_blank">[HTML]</a>
		<br>A key concept to make advanced graphics in Python.</p>
		
		<p><b>6. Plotting with seaborn</b>
		<a href="" target="_blank">[Github]</a>
		<a href="" target="_blank">[Kaggle]</a>
		<a href="https://plsms.github.io/wbk/06wbk.%20Plotting%20with%20seaborn.html" target="_blank">[HTML]</a>
		<br>The faster way to create complex graphics</p>
		
		<p><b>7. Faceting with seaborn</b>
		<a href="" target="_blank">[Github]</a>
		<a href="" target="_blank">[Kaggle]</a>
		<a href="https://plsms.github.io/wbk/07wbk.%20Faceting%20with%20seaborn.html" target="_blank">[HTML]</a>
		<br>Extend your graphical powers to capture more variables and patterns</p>
		
		<p><b>8. Multivariate plotting</b>
		<a href="" target="_blank">[Github]</a>
		<a href="" target="_blank">[Kaggle]</a>
		<a href="https://plsms.github.io/wbk/08wbk.%20Multivariate%20plotting.html" target="_blank">[HTML]</a>
		<br>Plotting in high dimensional spaces.</p>
		
		<p><b>9. Introduction to plotly (Optional)</b>
		<a href="" target="_blank">[Github]</a>
		<a href="" target="_blank">[Kaggle]</a>
		<a href="https://plsms.github.io/wbk/09wbk.%20Introduction%20to%20plotly%20(Optional).html" target="_blank">[HTML]</a>
		<br>Go from static graphics to interactive data visualization experiences.</p>
		
		<p><b>10. Grammar of graphics with plotnine (Optional)</b>
		<a href="" target="_blank">[Github]</a>
		<a href="" target="_blank">[Kaggle]</a>
		<a href="https://plsms.github.io/wbk/10wbk.%20Grammar%20of%20graphics%20with%20plotnine%20(Optional).html" target="_blank">[HTML]</a>
		<br>This Python implementation of R's ggplot2 library provides an incredible level of power for custom graphics.</p>
		
		<p><b>11. Time-series plotting (Optional)</b>
		<a href="" target="_blank">[Github]</a>
		<a href="" target="_blank">[Kaggle]</a>
		<a href="https://plsms.github.io/wbk/11wbk.%20Time-series%20plotting%20(Optional).html" target="_blank">[HTML]</a>
		<br>Specialized plots for time-series data</p>
		
	</div>
	
	<button class="accordion h2"><h2>SQL</h2></button>
	<div class="panel">
	
		<button class="accordion">Section 28 - Apriori</button>
		<div class="panel"><ul>
			<li>Apriori Intuition</li>
			<li><a href="https://github.com/plsms/Machine-Learning/blob/master/Part%2005%20-%20Association%20Rule%20Learning/Section%2028%20-%20Apriori/Apriori_Python/apriori.py" target="_blank">
			Apriori in Python</a></li>
				<ul>
				<li>Importing the libraries</li>
				<li>Data Preprocessing</li>
				<li>Training Apriori on the dataset</li>
				<li>Visualising the results</li>
				</ul>
			<li><a href="https://github.com/plsms/Machine-Learning/blob/master/Part%2005%20-%20Association%20Rule%20Learning/Section%2028%20-%20Apriori/Apriori-R/apriori.R" target="_blank">
			Apriori in R</a></li>
				<ul>
				<li>Data Preprocessing</li>
				<li>Training Apriori on the dataset</li>
				<li>Visualising the results</li>
				</ul>
		</ul></div>
		
		<button class="accordion">Section 29 - Eclat</button>
		<div class="panel"><ul>
			<li>Eclat Intuition</li>
			<li><a href="https://github.com/plsms/Machine-Learning/blob/master/Part%2005%20-%20Association%20Rule%20Learning/Section%2029%20-%20Eclat/Eclat/eclat.R" target="_blank">
			Eclat in R</a></li>
				<ul>
				<li>Data Preprocessing</li>
				<li>Training Eclat on the dataset</li>
				<li>Visualising the results</li>
				<p><a href="" target="_blank"><img src=""/></a></p>
				</ul>
		</ul></div>
		
		<button class="accordion">Section 30 - Part Recap</button>
		<div class="panel"></div>
	
	</div>
	
	<button class="accordion h2"><h2>R</h2></button>
	<div class="panel">
	
		<button class="accordion">Section 32 - Upper Confidence Bound (UCB)</button>
		<div class="panel"><ul>
			<li>The Multi-Armed Bandit Problem</li>
			<li>Upper Confidence Bound (UCB) Intuition</li>
			<li><a href="https://github.com/plsms/Machine-Learning/blob/master/Part%2006%20-%20Reinforcement%20Learning/Section%2032%20-%20Upper%20Confidence%20Bound%20(UCB)/UCB/random_selection.py" target="_blank">
			Random Selection in Python</a></li>
				<ul>
				<li>Importing the libraries</li>
				<li>Importing the dataset</li>
				<li>Implementing Random Selection</li>
				<li>Visualising the results</li>
				<p><a href="https://i.imgur.com/E8MsnPC.png" target="_blank"><img src="https://i.imgur.com/E8MsnPC.png"/></a></p>
				</ul>
			<li><a href="https://github.com/plsms/Machine-Learning/blob/master/Part%2006%20-%20Reinforcement%20Learning/Section%2032%20-%20Upper%20Confidence%20Bound%20(UCB)/UCB/upper_confidence_bound.py" target="_blank">
			Upper Confidence Bound in Python</a></li>
				<ul>
				<li>Importing the libraries</li>
				<li>Importing the dataset</li>
				<li>Implementing UCB</li>
				<p><a href="https://i.imgur.com/nuF9nK9.jpg" target="_blank"><img src="https://i.imgur.com/nuF9nK9.jpg"/></a></p>
				<li>Visualising the results</li>
				<p><a href="https://i.imgur.com/GbkgoC0.png" target="_blank"><img src="https://i.imgur.com/GbkgoC0.png"/></a></p>
				</ul>
			<li><a href="https://github.com/plsms/Machine-Learning/blob/master/Part%2006%20-%20Reinforcement%20Learning/Section%2032%20-%20Upper%20Confidence%20Bound%20(UCB)/UCB/random_selection.R" target="_blank">
			Random Selection in R</a></li>
				<ul>
				<li>Importing the dataset</li>
				<li>Implementing Random Selection</li>
				<li>Visualising the results</li>
				<p><a href="https://i.imgur.com/1urTW3J.png" target="_blank"><img src="https://i.imgur.com/1urTW3J.png"/></a></p>
				</ul>
			<li><a href="https://github.com/plsms/Machine-Learning/blob/master/Part%2006%20-%20Reinforcement%20Learning/Section%2032%20-%20Upper%20Confidence%20Bound%20(UCB)/UCB/upper_confidence_bound.R" target="_blank">
			Upper Confidence Bound in R</a></li>
				<ul>
				<li>Importing the dataset</li>
				<li>Implementing UCB</li>
				<li>Visualising the results</li>
				<p><a href="https://i.imgur.com/uqp01rY.png" target="_blank"><img src="https://i.imgur.com/uqp01rY.png"/></a></p>
				</ul>
		</ul></div>
		
		<button class="accordion">Section 33 - Thompson Sampling</button>
		<div class="panel"><ul>
			<li>Thompson Sampling Intuition</li>
			<li>Algorithm Comparison: UCB vs Thompson Sampling</li>
			<li><a href="https://github.com/plsms/Machine-Learning/blob/master/Part%2006%20-%20Reinforcement%20Learning/Section%2033%20-%20Thompson%20Sampling/Thompson_Sampling/thompson_sampling.py" target="_blank">
			Thompson Sampling in Python</a></li>
				<ul>
				<li>Importing the libraries</li>
				<li>Importing the dataset</li>
				<li>Implementing Thompson Sampling</li>
				<p><a href="https://i.imgur.com/re1fNzl.jpg" target="_blank"><img src="https://i.imgur.com/re1fNzl.jpg"/></a></p>
				<li>Visualising the results - Histogram</li>
				<p><a href="https://i.imgur.com/bE4kFq8.png" target="_blank"><img src="https://i.imgur.com/bE4kFq8.png"/></a></p>
				</ul>
			<li><a href="https://github.com/plsms/Machine-Learning/blob/master/Part%2006%20-%20Reinforcement%20Learning/Section%2033%20-%20Thompson%20Sampling/Thompson_Sampling/thompson_sampling.R" target="_blank">
			Thompson Sampling in R</a></li>
				<ul>
				<li>Importing the dataset</li>
				<li>Implementing Thompson Sampling</li>
				<li>Visualising the results</li>
				<p><a href="https://i.imgur.com/PQRJJEP.png" target="_blank"><img src="https://i.imgur.com/PQRJJEP.png"/></a></p>
				</ul>
		</ul></div>
		
		<button class="accordion">Section 34 - Part Recap</button>
		<div class="panel"></div>
	
	</div>
	
	<button class="accordion h2"><h2>Deep Learning</h2></button>
	<div class="panel">
	
		<button class="accordion">Section 36 - Natural Language Processing</button>
		<div class="panel"><ul>
			<li>Natural Language Processing Intuition</li>
			<li><a href="https://github.com/plsms/Machine-Learning/blob/master/Part%2007%20-%20Natural%20Language%20Processing/Section%2036%20-%20Natural%20Language%20Processing/Natural_Language_Processing/natural_language_processing.py" target="_blank">
			Natural Language Processing in Python</a></li>
				<ul>
				<li>Importing the libraries</li>
				<li>Importing the dataset</li>
				<li>Cleaning the texts</li>
				<li>Creating the Bag of Words model</li>
				<li>Splitting the dataset into the Training set and Test set</li>
				<li>Fitting Naive Bayes to the Training set</li>
				<li>Predicting the Test set results</li>
				<li>Making the Confusion Matrix</li>
			<li><a href="https://github.com/plsms/Machine-Learning/blob/master/Part%2007%20-%20Natural%20Language%20Processing/Section%2036%20-%20Natural%20Language%20Processing/Natural_Language_Processing/natural_language_processing.R" target="_blank">
			Natural Language Processing in R</a></li>
				<ul>
				<li>Importing the dataset</li>
				<li>Cleaning the texts</li>
				<li>Creating the Bag of Words model</li>
				<li>Importing the dataset</li>
				<li>Encoding the target feature as factor</li>
				<li>Splitting the dataset into the Training set and Test set</li>
				<li>Fitting Random Forest Classification to the Training set</li>
				<li>Predicting the Test set results</li>
				<li>Making the Confusion Matrix</li>
				<li>Visualising</li>
				</ul>
		</ul></div>
		
		<button class="accordion">Section 37 - Part Recap</button>
		<div class="panel"></div>
	
	</div>
	
	<button class="accordion h2"><h2>Machine Learning for Insights</h2></button>
	<div class="panel">
	
		<button class="accordion">Section 38 - What is Deep Learning?</button>
		<div class="panel"></div>
	
		<button class="accordion">Section 39 - Artificial Neural Networks (ANN)</button>
		<div class="panel"><ul>
			<li>Plan of attack</li>
			<li>The Neuron</li>
			<li>The Activation Function</li>
			<li>How do Neural Networks work?</li>
			<li>How do Neural Networks learn?</li>
			<li>Gradient Descent</li>
			<li>Stochastic Gradient Descent</li>
			<li>Backpropagation</li>
			<li>Business Problem Description</li>
			<li><a href="https://github.com/plsms/Machine-Learning/blob/master/Part%2008%20-%20Deep%20Learning/Section%2039%20-%20Artificial%20Neural%20Networks%20(ANN)/Artificial_Neural_Networks/ann.py" target="_blank">
			Artificial Neural Networks in Python</a></li>
				<ul>
				<li>Installing Theano, Tensorflow and Keras</li>
				<li>Part 1 - Data Preprocessing</li>
					<ul>
					<li>Importing the libraries</li>
					<li>Importing the dataset</li>
					<li>Encoding categorical data</li>
					<li>Splitting the dataset into the Training set and Test set</li>
					<li>Feature Scaling</li>
					</ul>
				<li>Part 2 - Making the ANN</li>
				<a href="https://i.imgur.com/cvFBSTy.jpg" target="_blank"><img src="https://i.imgur.com/cvFBSTy.jpg"/></a>
					<ul>
					<li>Importing the Keras libraries and packages</li>
					<li>Initialising the ANN</li>
					<li>Adding the input layer and the first hidden layer</li>
					<li>Adding the second hidden layer</li>
					<li>Adding the output layer</li>
					<li>Compiling the ANN</li>
					<li>Fitting the ANN to the Training set</li>
					</ul>
				<li>Part 3 - Making the predictions and evaluating the model</li>
					<ul>
					<li>Predicting the Test set results</li>
					<li>Making the Confusion Matrix</li>
					</ul>
				</ul>
			<li><a href="https://github.com/plsms/Machine-Learning/blob/master/Part%2008%20-%20Deep%20Learning/Section%2039%20-%20Artificial%20Neural%20Networks%20(ANN)/Artificial_Neural_Networks/ann.R" target="_blank">
			Artificial Neural Networks in R</a></li>
				<ul>
				<li>Importing the dataset</li>
				<li>Encoding the categorical variables as factors</li>
				<li>Splitting the dataset into the Training set and Test set</li>
				<li>Feature Scaling</li>
				<li>Fitting ANN to the Training set</li>
				<li>Predicting the Test set results</li>
				<li>Making the Confusion Matrix</li>
		</ul></div>
		
		<button class="accordion">Section 40 - Convolutional Neural Networks (CNN)</button>
		<div class="panel"><ul>
			<li>Plan of attack</li>
			<li>What are convolutional neural networks?</li>
			<li>Step 1 - Convolution Operation</li>
			<li>Step 1(b) - ReLU Layer</li>
			<li>Step 2 - Pooling</li>
			<li>Step 3 - Flattening</li>
			<li>Step 4 - Full Connection</li>
			<li>Softmax & Cross-Entropy</li>
			<li><a href="https://github.com/plsms/Machine-Learning/blob/master/Part%2008%20-%20Deep%20Learning/Section%2040%20-%20Convolutional%20Neural%20Networks%20(CNN)/Convolutional_Neural_Networks/cnn.py" target="_blank">
			Convolutional Neural Networks in Python</a></li>
				<ul>
				<li>Installing Theano, Tensorflow and Keras</li>
				<li>Part 1 - Building the CNN</li>
					<ul>
					<li>Importing the Keras libraries and packages</li>
					<li>Initialising the CNN</li>
					<li>Step 1 - Convolution</li>
					<li>Step 2 - Pooling</li>
					<li>Adding a second convolutional layer</li>
					<li>Step 3 - Flattening</li>
					<li>Step 4 - Full connection</li>
					<li>Compiling the CNN</li>
					</ul>
				<li>Part 2 - Fitting the CNN to the images</li>
					<ul>
					<li><a href="https://keras.io/preprocessing/image/" target="_blank">Image Preprocessing - Keras Documentation</a></li>
					</ul>
				</ul>
		</ul></div>
		
		<button class="accordion">Section 41 - Part Recap</button>
		<div class="panel"></div>
	
	</div>
	
</section>

<aside id="sidebar">
	
	<a href="https://plsms.github.io"><b>Home</b></a><br>
		<br><li><a href="https://plsms.github.io/kaggle.html">Kaggle</a></li>
		<br><li><a href="https://plsms.github.io/mlaz.html">Machine Learning A-Z</a></li>
	
	<br><p class="repo-owner">Site maintained by <a href="https://github.com/plsms" target="_blank">PLSMS</a>.</p>
	
</aside>

</div></div>
	
<script>
var acc = document.getElementsByClassName("accordion");
var i;

for (i = 0; i < acc.length; i++) {
    acc[i].addEventListener("click", function() {
        this.classList.toggle("active");
        var panel = this.nextElementSibling;
        if (panel.style.display === "block") {
            panel.style.display = "none";
        } else {
            panel.style.display = "block";
        }
    });
}
</script>

</body>
</html>
